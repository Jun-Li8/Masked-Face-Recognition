{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "361f8f17-aa75-4f00-ad00-095ebbd8400e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image,ImageOps\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de6f9343-2f5f-4234-8501-aa0136d033c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_DIR = os.path.abspath('')\n",
    "data_dir = os.path.join(BASE_DIR, \"recognizer_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e80fd83b-b4c7-4cde-b1eb-8745f1fd989c",
   "metadata": {},
   "outputs": [],
   "source": [
    "face_cascade = cv2.CascadeClassifier('../data/haarcascade_frontalface_alt2.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbff6716-3203-4218-b650-d1bca43945ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "current_label = 0\n",
    "labels = {}\n",
    "y_labels = []\n",
    "x_train = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cabe5b0d-15cf-4785-80b2-b657249889d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_img(imgs):\n",
    "    max_i = 0;\n",
    "    for i in range(imgs.shape[0]):\n",
    "        if (imgs[i,2]*imgs[i,3]) > (imgs[max_i,2]*imgs[max_i,3]):\n",
    "            max_i = i\n",
    "    \n",
    "    return [imgs[max_i,:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c33b3eb0-1839-48d9-bbb6-40bea33541e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex\n",
      "(371, 371)\n",
      "alex\n",
      "(136, 136)\n",
      "alex\n",
      "(342, 342)\n",
      "alex\n",
      "(92, 92)\n",
      "alex\n",
      "(48, 48)\n",
      "jun\n",
      "(91, 91)\n",
      "jun\n",
      "(116, 116)\n",
      "jun\n",
      "(148, 148)\n",
      "jun\n",
      "jun\n",
      "(117, 117)\n",
      "jun\n",
      "(135, 135)\n",
      "jun\n",
      "(113, 113)\n",
      "jun\n",
      "(120, 120)\n",
      "jun\n",
      "(118, 118)\n",
      "jun\n",
      "jun\n",
      "(105, 105)\n",
      "jun\n",
      "(103, 103)\n",
      "jun\n",
      "(91, 91)\n",
      "jun\n",
      "(89, 89)\n",
      "medet\n",
      "(250, 250)\n",
      "medet\n",
      "(119, 119)\n",
      "medet\n",
      "(360, 360)\n",
      "medet\n",
      "(219, 219)\n",
      "medet\n",
      "(408, 408)\n",
      "medet\n",
      "(113, 113)\n",
      "medet\n",
      "(347, 347)\n",
      "medet\n",
      "(190, 190)\n",
      "medet\n",
      "(313, 313)\n",
      "medet\n",
      "(49, 49)\n",
      "medet\n",
      "(201, 201)\n",
      "medet\n",
      "(119, 119)\n",
      "medet\n",
      "medet\n",
      "(334, 334)\n",
      "medet\n",
      "(360, 360)\n",
      "medet\n",
      "(83, 83)\n",
      "other\n",
      "(48, 48)\n",
      "other\n",
      "(111, 111)\n",
      "other\n",
      "(98, 98)\n",
      "other\n",
      "(43, 43)\n",
      "other\n",
      "(45, 45)\n",
      "other\n",
      "other\n",
      "(74, 74)\n",
      "other\n",
      "(66, 66)\n"
     ]
    }
   ],
   "source": [
    "for root, dirs, files in os.walk(data_dir):\n",
    "    for file in files:\n",
    "        if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "            path = os.path.join(root,file)\n",
    "            label = os.path.basename(root)\n",
    "\n",
    "            if label not in labels:\n",
    "                labels[label] = current_label\n",
    "                current_label += 1\n",
    "            \n",
    "            #Open image as gray and resize \n",
    "            image = cv2.imread(path)\n",
    "            gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "            # resized_img = cv2.resize(gray, (240, 320), interpolation=cv2.INTER_AREA)\n",
    "            final_image = np.array(gray,'uint8')\n",
    "\n",
    "            faces = face_cascade.detectMultiScale(final_image,scaleFactor=1.01,minNeighbors=5)\n",
    "            print(label)\n",
    "            if (len(faces) > 1):\n",
    "                faces = get_max_img(faces)\n",
    "            for (x,y,w,h) in faces:\n",
    "                face_crop = final_image[y:y+h, x:x+w]\n",
    "                face_crop = cv2.resize(face_crop, (128, 128))\n",
    "                x_train.append(face_crop)\n",
    "                y_labels.append(labels[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d95fa6d5-448e-424c-b891-e32c50417739",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"mask_face_labels.p\",'wb') as f:\n",
    "    pickle.dump(labels,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "87de5363-d0af-42d3-98a4-032969605fbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def get_max_img(imgs):\n",
    "#     max_i = 0;\n",
    "#     for i in range(imgs.shape[0]):\n",
    "#         if (imgs[i,2]*imgs[i,3]) > (imgs[max_i,2]*imgs[max_i,3]):\n",
    "#             max_i = i\n",
    "    \n",
    "#     return [imgs[max_i,:]]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15117ddb-fa49-4f52-85fa-9f3c668bc46f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alex\n",
      "[[143 144 139 ... 156 154 154]\n",
      " [148 155 140 ... 157 156 156]\n",
      " [141 157 148 ... 157 156 156]\n",
      " ...\n",
      " [151 152 153 ... 170 171 171]\n",
      " [146 147 148 ... 169 169 170]\n",
      " [144 145 145 ... 168 168 169]]\n",
      "alex\n",
      "[[157 153 141 ... 120 122 124]\n",
      " [154 155 145 ... 122 124 124]\n",
      " [151 157 149 ... 121 123 122]\n",
      " ...\n",
      " [165 166 167 ... 143 143 146]\n",
      " [164 165 167 ... 142 142 146]\n",
      " [164 165 168 ... 143 143 147]]\n",
      "alex\n",
      "[[ 87  81  85 ... 116 114 112]\n",
      " [ 90  87  84 ... 120 117 116]\n",
      " [ 91  93  88 ... 122 121 122]\n",
      " ...\n",
      " [155 154 156 ... 142 144 145]\n",
      " [154 151 150 ... 143 148 148]\n",
      " [155 152 152 ... 153 149 149]]\n",
      "alex\n",
      "[[ 47  40  38 ...  53  51 168]\n",
      " [ 41  35  37 ...  52  37 141]\n",
      " [ 37  34  38 ...  52  41 115]\n",
      " ...\n",
      " [148 179 210 ... 103 104 104]\n",
      " [107 112 132 ... 102 103 102]\n",
      " [126 110 101 ...  99 100  99]]\n",
      "alex\n",
      "[[ 88  77  76 ... 120 121 125]\n",
      " [ 78  66  72 ... 119 122 126]\n",
      " [ 72  74  76 ... 128 131 132]\n",
      " ...\n",
      " [174 175 175 ... 136 135 132]\n",
      " [173 174 175 ... 132 129 127]\n",
      " [172 172 174 ... 130 127 126]]\n"
     ]
    }
   ],
   "source": [
    "# for root, dirs, files in os.walk(data_dir):\n",
    "#     for file in files:\n",
    "#         if file.endswith(\"png\") or file.endswith(\"jpg\"):\n",
    "#             path = os.path.join(root,file)\n",
    "#             label = os.path.basename(root)\n",
    "\n",
    "#             if label not in labels:\n",
    "#                 labels[label] = current_label\n",
    "#                 current_label += 1\n",
    "            \n",
    "#             #Open image as gray and resize \n",
    "#             image = cv2.imread(path)\n",
    "#             gray = cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n",
    "#             final_image = np.array(gray,'uint8')\n",
    "#             faces = np.array(face_cascade.detectMultiScale(final_image,scaleFactor=1.01,minNeighbors=5))\n",
    "#             print(label)\n",
    "#             if (faces.shape[0] > 1):\n",
    "#                 faces = get_max_img(faces)\n",
    "#             for (x,y,w,h) in faces:\n",
    "#                 face_crop = final_image[y:y+h, x:x+w]\n",
    "#                 print(face_crop.shape)\n",
    "#                 face_crop = cv2.resize(face_crop, (128, 128))\n",
    "#                 x_train.append(face_crop)\n",
    "#                 y_labels.append(labels[label])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "038dacc4-6a53-4ab6-bb8f-2301ee0bc21d",
   "metadata": {},
   "outputs": [],
   "source": [
    "LBPHS = cv2.face.LBPHFaceRecognizer_create()\n",
    "LBPHS.train(x_train, np.array(y_labels))\n",
    "LBPHS.save(\"models/LBPHF.yml\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6043b8ef-8e1f-4726-8352-7af693243801",
   "metadata": {},
   "outputs": [],
   "source": [
    "EigenFace=cv2.face.EigenFaceRecognizer_create()\n",
    "EigenFace.train(x_train, np.array(y_labels))\n",
    "EigenFace.write('models/Eigen.yml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4930f6a0-3d7c-47bc-b1bc-a82f40a3b288",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
