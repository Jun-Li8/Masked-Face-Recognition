{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6e2b2c81-e302-4f2a-9262-6ce9c92c90a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import RMSprop\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "import cv2\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, Input, ZeroPadding2D, BatchNormalization, Activation, MaxPooling2D, Flatten, Dense,Dropout\n",
    "from keras.models import Model, load_model\n",
    "from keras.callbacks import TensorBoard, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.utils import shuffle\n",
    "import imutils\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "52c1026c-7333-431c-8c01-32c84a548641",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg19 import VGG19\n",
    "from keras.applications.vgg19 import preprocess_input\n",
    "from keras import Sequential\n",
    "from keras.layers import Flatten, Dense\n",
    "from keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "947168b3-d554-429f-a968-ce4007a3bf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_dir = './Test'\n",
    "# test_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "# test_generator = test_datagen.flow_from_directory(directory=test_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdca32dd-00e5-43d2-8867-423782371555",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 10011 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "train_dir = './Train'\n",
    "train_datagen = ImageDataGenerator(rescale=1.0/255, horizontal_flip=True, zoom_range=0.2,shear_range=0.2)\n",
    "train_generator = train_datagen.flow_from_directory(directory=train_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d605c867-5f0c-4bb1-9baf-d2af0bfadda9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1792 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "val_dir = './Validation'\n",
    "val_datagen = ImageDataGenerator(rescale=1.0/255)\n",
    "val_generator = val_datagen.flow_from_directory(directory=val_dir,target_size=(128,128),class_mode='categorical',batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "324933ec-1514-45a2-a77b-366f221e21ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# model =Sequential([\n",
    "#     Conv2D(100, (3,3), activation='relu', input_shape=(128, 128, 3)),\n",
    "#     MaxPooling2D(2,2),\n",
    "    \n",
    "#     Conv2D(100, (3,3), activation='relu'),\n",
    "#     MaxPooling2D(2,2),\n",
    "    \n",
    "#     Flatten(),\n",
    "#     Dropout(0.5),\n",
    "#     Dense(50, activation='relu'),\n",
    "#     Dense(2, activation='sigmoid')\n",
    "# ])\n",
    "# model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1095835f-0776-435d-8b43-90f757ab3f97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg19/vgg19_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "80142336/80134624 [==============================] - 4s 0us/step\n",
      "80150528/80134624 [==============================] - 4s 0us/step\n"
     ]
    }
   ],
   "source": [
    "vgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n",
    "\n",
    "for layer in vgg19.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "model =Sequential([\n",
    "    vgg19,\n",
    "    Flatten(),\n",
    "    Dense(2, activation='sigmoid')\n",
    "])\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b6939f38-3fef-47fb-971c-7e8a8aea6343",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint = ModelCheckpoint('model3-{epoch:03d}.model',monitor='val_loss',verbose=0,save_best_only=True,mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42c980e1-6496-4207-9419-512adebff4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit_generator(generator=train_generator,\n",
    "                              steps_per_epoch=len(train_generator)//32,\n",
    "                              epochs=20,validation_data=val_generator,\n",
    "                              validation_steps=len(val_generator)//32,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8b428f78-e1d6-4e99-be70-7b4dc8bdf744",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\DrNuj\\AppData\\Local\\Temp/ipykernel_10380/4062518945.py:1: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
      "  history = model.fit_generator(train_generator,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.1891 - acc: 0.9199INFO:tensorflow:Assets written to: model3-001.model\\assets\n",
      "313/313 [==============================] - 50s 151ms/step - loss: 0.1891 - acc: 0.9199 - val_loss: 0.0640 - val_acc: 0.9800\n",
      "Epoch 2/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0707 - acc: 0.9749INFO:tensorflow:Assets written to: model3-002.model\\assets\n",
      "313/313 [==============================] - 51s 163ms/step - loss: 0.0707 - acc: 0.9749 - val_loss: 0.0319 - val_acc: 0.9900\n",
      "Epoch 3/10\n",
      "313/313 [==============================] - 52s 164ms/step - loss: 0.0464 - acc: 0.9842 - val_loss: 0.0347 - val_acc: 0.9850\n",
      "Epoch 4/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0439 - acc: 0.9837- ETA: 4s - loINFO:tensorflow:Assets written to: model3-004.model\\assets\n",
      "313/313 [==============================] - 59s 187ms/step - loss: 0.0439 - acc: 0.9837 - val_loss: 0.0204 - val_acc: 0.9925\n",
      "Epoch 5/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0313 - acc: 0.9879INFO:tensorflow:Assets written to: model3-005.model\\assets\n",
      "313/313 [==============================] - 57s 183ms/step - loss: 0.0313 - acc: 0.9879 - val_loss: 0.0196 - val_acc: 0.9925\n",
      "Epoch 6/10\n",
      "313/313 [==============================] - ETA: 0s - loss: 0.0344 - acc: 0.9873INFO:tensorflow:Assets written to: model3-006.model\\assets\n",
      "313/313 [==============================] - 60s 192ms/step - loss: 0.0344 - acc: 0.9873 - val_loss: 0.0135 - val_acc: 0.9950\n",
      "Epoch 7/10\n",
      "313/313 [==============================] - 61s 194ms/step - loss: 0.0369 - acc: 0.9866 - val_loss: 0.0271 - val_acc: 0.9900\n",
      "Epoch 8/10\n",
      "313/313 [==============================] - 58s 184ms/step - loss: 0.0307 - acc: 0.9888 - val_loss: 0.0187 - val_acc: 0.9962\n",
      "Epoch 9/10\n",
      "313/313 [==============================] - 70s 223ms/step - loss: 0.0294 - acc: 0.9896 - val_loss: 0.0207 - val_acc: 0.9937\n",
      "Epoch 10/10\n",
      "313/313 [==============================] - 81s 258ms/step - loss: 0.0289 - acc: 0.9904 - val_loss: 0.0195 - val_acc: 0.9912\n"
     ]
    }
   ],
   "source": [
    "history = model.fit_generator(train_generator,\n",
    "                              epochs=10,\n",
    "                              validation_data=val_generator,\n",
    "                              callbacks=[checkpoint])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474c1b38-73b3-44db-8276-e37111fe45cb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
